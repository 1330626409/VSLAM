# 直接稀疏法里程计

## 摘要  
DSO是一种新的基于直接法和稀疏法的视觉里程计，该方法将最小化光度误差模型和所有模型参数相结合。为了满足实时性，本文没有对图像进行光滑处理，而是对整个图像均匀采样。因为本文的方法不依赖于关键点检测和特征描述符，所以它可以在整个图像内采样具有强度梯度的像素点，包括白墙上的边缘和强度平滑变换的像素点，所提出的方法集成了完整的光度标定，考虑了完整的曝光时间，透镜晕影，非线性响应函数的影响。在三个不同的数据集进行了测试评估。实验表明，在跟踪精度和鲁棒性方面该方法明显优于其他的直接法和间接法。

## 介绍  

### 1. 直接法 VS 间接法  
直接法和间接法的本质都是一个概率模型，将含噪声的测量Y作为输入并且计算未知的模型参数的估计量。求解时通常采用最大似然方法，找到最大化实际测量概率的模型参数：  
$$X^*:=argmax_XP(Y|X)$$

间接法对测量数据进行预处理以产生中间层表示，之后将中间层的数据作为测量Y输入到概率模型中，以估计三维环境模型和相机运动。通常第一步是通过稀疏的特征点提取和匹配来实现的，然而也可以采用更加稠密的光流或者提取直线特征或曲线特征。  
而直接法直接跳过预处理步骤，直接使用像素值作为概率模型中的测量Y。  
对于摄像头而言，由于传感器提供光度测量，因此直接法优化的是光度误差，而间接法通过预处理，计算出地图点坐标或者光流向量，因此优化的是几何误差。  
### 2. 稀疏法 VS 稠密法  
稀疏法仅使用一小部分特殊像素点（比如边角），稠密法则使用图片中的所有像素，中间法（半稠密法）不重建完整的环境模型，但是仍然使用大部分具有良好连接和约束的像素点。  
在稀疏法中没有邻域的概念，并且几何参数（特征点位置）在给定相机位姿和内参的情况下是独立的。稠密法（半稠密法）利用所使用的图像区域的连通性来形成几何先验信息。如果仅使用被动视觉来重建稠密三维环境，几何先验是必须的。
>间接法+稀疏法  
这是应用最广泛的方法，通过匹配的特征点集，对环境模型和相机位姿进行估计。

>稠密法+间接法  
通过匹配的光流场，重建稠密的环境模型。  

>稠密法+直接法  
不仅使用几何先验信息，同时通过最小化光度误差来重建稠密的环境模型。相关工作有DTAM，LSD-SLAM  

>稀疏法+直接法  
该方法不考虑几何先验信息，直接优化光度误差。

### 3. 为什么采用  
本文采用直接法和稀疏法相结合的方法主要是基于以下考虑。  
(1)直接法  
基于特征点的直接法的主要优点是它对现有的摄像头拍摄的图像中存在的光度误差和几何失真具有高度鲁棒性。  
比如自动曝光变化，非线性响应函数（伽马矫正/白平衡），透镜衰减（渐晕），去耦合伪像和由卷帘快门引起的几何失真。  
但是，大多数应用于机器视觉相关的设备其配备的摄像头提供的图像数据是专门用于机器视觉算法的，而不仅仅用于人类娱乐消费。这些摄像头会提供完整的传感器模型，并且以最适合视觉算法处理的方式来提供数据，例如自动曝光和伽马矫正不是未知的噪声源，而是被并入到模型中，使得所获得的数据更准确，而且由于直接法利用整个图片中的像素强度信息，所以它将受益于更精确的传感器模型。  
直接法的优点之一是它不需要提取可重复识别的特征点，从而允许更细致的几何表示方法（逆深度值）。此外，直接法可从所有图像像素点中采样，生成更完整的环境模型，这提高了其在若纹理特征中使用的鲁棒性。  

(2)稀疏法  
稠密法的主要缺点是其利用的几何先验信息使得优化时需要考虑地图点之间的相关性，导致实时的联合优化估计变得不可行。  
因此现有的稠密法或半稠密法采用两种方法：  
>>a)忽略或者粗略近似几何参数（橙色）的相关性以及几何参数和相机位姿之间的相关性  
b)采用Primal-dual等方法对右下角子矩阵进行求解。

尽管稠密法使得重建的环境模型更加完整，细致，美观，但是几何先验信息会额外导入误差，当算法在大尺寸环境长时间运行时，反而会影响算法的精确，这个问题是通过提高几何先验信息的准确性和可靠性来解决。

![稀疏法VS稠密法](https://github.com/MRwangmaomao/VSLAM/blob/master/DSO/pic/sparse_vs_dense.png)  
左：稀疏法Hessian矩阵：由于右下角子矩阵是对角线矩阵，因此可通过舒尔补有效地提高计算效率。右：稠密法Hessian矩阵：几何先验信息会在右下角子矩阵中添加元素，通常是不规则的，不仅增大了计算量，还使得计算变得复杂，为了简单起见，上图并未包括相机内参。

### 4. 主要贡献
1. 提出了单目直接法和稀疏法结合的视觉里程计。目前是直接法中唯一优化所有模型的方法，包括相机位姿，相机内参和地图几何参数的（逆深度值）。
2. 采用滑动窗口优化算法，边缘化旧的图像帧和不在视角范围内的地图点。但是与现有方法相比，充分利用了相机光度标定（透镜衰减，伽马校正，已知的曝光时间）进一步提高了视觉里程计的精度和鲁棒性。
3. 可以在笔记本电脑上实时运行。在三个数据及上进行测试，实验表明在跟踪精度和鲁棒性方面该方法显著优于其他的直接法和间接法。当减少优化的关键帧和地图点数量时，计算速度可以提高5倍但是表现仍然超越最先进的间接法。

## 直接稀疏法模型  
DSO采用最小光度误差优化算法，并且考虑了**光度标定模型**，其优化范围不是所有帧，而是由最近帧及其前几帧形成的**滑动窗口**。与现有的直接法不同，DSO优化**所有参数模型**（包括相机内参，相机外参，逆深度值），但算法效率与间接法中常用的bundle adjustment算法相近。同时采用和其他直接法相同的地图点表示方法，即三维点被表示为相应坐标下的**逆深度值**，因此只有一个自由度。

### 1. 标定  
本文对图像形成过程进行了全面建模，除了相机几何模型---其将3D点投影到2D图像上。还考虑了相机的光度模型---其将像素接收的真实世界能量映射为相应的强度值。需要注意的是间接法由于提取的特征点和描述子通常对于光度变化具有不变形（高鲁棒性），因此间接法中使用光度模型基本没有作用所以大家都忽略了。  
##### 1.1 相机几何标定  
虽然本文使用了广角相机，但简单起见，我们采用针孔相机模型，只是在预处理步骤中去除径向失真，这也使得本文的方法与其他使用针孔相机模型的方法具有可比较性。在本文中，我们将用 $\pi_c:R^3\rarr \Omega$ 表示投影，用$\pi_c^(-1):\Omega * R^3\rarr R^3$ 表示反投影，其中c表示相机的内参（对于针孔模型，内参为焦距和图像原点相对于光心成像点的纵横偏移量）。注意，类似于[参考文献1](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7353366)，我们的方法可以扩展到其他相机模型，但会增加计算量。
##### 1.2 相机光度标定  
采用[参考文献2](https://arxiv.org/pdf/1607.02555.pdf)中提及的光度模型，考虑了非线性响应函数$G:R\rarr [0,255]$以及透镜衰减（晕影） $V:\Omega \rarr [0,1]$。下图展示了一个TUM monoVO 数据集中的光度模型参数，光度模型可以由下式表示：
$$I_i(x)=G(t_iV(x)B_i(x))$$  
其中$B_i$和$I_i$分别是帧$i$中的辐照度和观测到的像素强度，$t_i$是曝光时间。  
测试中用到的每幅图像都会通过光度模型进行校正，然后再输入到视觉里程计模型中。
$$I_i^{'}(x):=t_iB_i(x)=\frac{G^{-1}(I_i(x))}{V(x)}$$  
![光度标定](https://github.com/MRwangmaomao/VSLAM/blob/master/DSO/pic/光度标定.png)  
上图：图一中采用的相机的逆非线性响应函数$G^{-1}$ 和透镜衰减V.下图：一个包含室内和室外场景的视频序列的曝光时间（以毫秒为单位）。注意它涵盖了0.018到10.5ms，变化超过500倍。我们在光度标定模型中充分地考虑其影响，而不是将其视为未知噪声。

### 2. 模型公式
参考帧$I_i$中点$P \in \Omega_i$的光度误差是通过目标帧$I_j$中相应点的邻域上的光度值的加权SSD来计算。经过试验发现，按图4的模式（邻域包含8个像素）进行计算时，可在计算效率、动态

![误差计算模式](https://github.com/MRwangmaomao/VSLAM/blob/master/DSO/pic/误差计算模式.png)  
**图4.误差计算模式**  模式用于计算光度误差。忽略右下像素以计算SSE。注意，由于每个点都有一个变量（逆深度值），并且未正则化。为了便于仅对两个帧进行优化时所有模型参数都具有良好约束，我们需要。图19评估了误差计算模式对跟踪精度的影响。

[1] D.Caruso, J. Engel, and D. Cremers. Large-scale direct SLAM for omnidirectionalcameras. In International Conference onIntelligent Robot Systems (IROS), 2015. 4  
[2] J.Engel, V. Usenko, and D. Cremers. A photometrically calibrated benchmark formonocular visual odometry. In arXivpreprint arXiv, 2016. 4, 10, 11,12, 16  
[3]H.Jin, P. Favaro, and S. Soatto. A semi-direct approach to structure from motion.The Visual Computer, 19(6):377– 394,2003. 2, 5    
[4] J.Engel, J. Stueckler, and D. Cremers. Large-scale direct slam with stereocameras. In International Conference onIntelligent Robot Systems (IROS), 2015. 5  
[5] J.Civera, A. Davison, and J. Montiel. Inverse depth parametrization for monocularSLAM. Transactions on Robotics,24(5):932–945, 2008. 6  
[6] S.Leutenegger, S. Lynen, M. Bosse, R. Siegwart, and P. Furgale. Keyframe-basedvisual–inertial odometry using nonlinear optimization. International Journal of Robotics Research, 34(3):314–334, 2015. 3, 6, 7, 13  
[7] G.P. Huang, A. I. Mourikis, and S. I. Roumeliotis. A first-estimates Jacobian EKFfor improving SLAM consistency. In InternationalSymposium on Experimental Robotics, 2008. 6